{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![nlp tasks ](./nlpTasks.png) -->\n",
    "<p align=\"center\">\n",
    "<img src=\"../images/nlpTasks.png\" width=\"70%\"  >\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP PipeLine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Acquisition :** is the first step in NLP Pipeline ,which is get the necessary data to solve  a given NLP problem (some of ways that you can collect data with ,use public data set , U.S consensus bearu , webScrapping,product intervention  , data augmentation   )\n",
    "\n",
    "1.  **Text extraction & Clean up :** the data we got is very raw it has a lot of extra information so we only need useful information  out of it  and then doing some cleaning on top of it \n",
    "    - discard irrelevant information\n",
    "    - spelling correction + remove \\n \\n \n",
    "\n",
    "\n",
    "1. **PreProcessing**\n",
    "    ![preProcessing](../images/preProcessing.png)\n",
    "\n",
    "\n",
    "    1. Sentence Segmentation(Sentence Tokenization ) : which is taking the data that we have cleaned up  and split into sentences (splitting sentence should be collaborate a lot of rules  of grammers of specific language to build a good sentence splitter (tokanizer ))\n",
    "    \n",
    "    > tokenization is process of splitting text into meaningful segments \n",
    "\n",
    "    1. Word Tokenization : once we have created separated sentences , the next step is  would be create seperate words  once we create seperated words then we can  create a Machine Learning Model and build our NLP application \n",
    "\n",
    "    1. Stemming : is basically using some fix rules  to try to come up with  a **Base Word** but stemming usually is not enough cause we have lot of verb tenses \n",
    "\n",
    "    ![stemming ve lemmatization ](../images/stemming&lemmatization.png)\n",
    "\n",
    "\n",
    "    4. Lemmatization :  mapping words to its **Base word**\n",
    "\n",
    "    ![stemming2PracticalNLPbook](../images/stemming2.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now what is our end goal is create a classifier than can take the text and classified it  , now after the steps above we get the texts but machine learnign models do not understand text they always asks for **numbers**\n",
    "so we need some techniques that can convert words into numbers \n",
    "\n",
    "4. the process of converting words to numbers is called  **Feature Engineering** ( there are various popular techniques to do this : TF-IDF , ONE HOT ENCODING , WORD EMBEDDING )for now let say that these are good ways of converting words into numbers  so that these numbers presents these words in accurate way\n",
    "\n",
    "\n",
    "\n",
    "5. **Model building :** there are various classification techniques in ML so we need to find the model that give us best accuracy and the way to do it is by using (GridSearchCv)\n",
    "\n",
    "\n",
    "<!--  TODO : burada resim var  -->\n",
    "\n",
    "6. **Evaluation :** now when we are evaluating our model  we can use something called confusion matrix \n",
    "on the confusion matrix on the X-axis : we have truth \n",
    "y-axis : we have prediciton  \n",
    "so any thing is not in digonal is our wrong prediction \n",
    "by looking at confusion matrix we can see how confuse our model is \n",
    "but if our model is not confuse if is very accurate we can see all the numbers in the diagonal  , and every where else we gonna see zero .\n",
    "When we are building our ML model  we can use different  metric like (accuracy , precision , recall, f1 score )  to figure out if the model is good or not  \n",
    "  > if things don't look good  we try again  and try to do revisions \n",
    "\n",
    "7. **Deployment :** deploy your model on end to end Machine learning platforms or on the clouds \n",
    "\n",
    "8. **Monitor & update :** once the services deployed of course  you do need to monitor and update periodically  when you deploy to production and when it starts serving request , you have  to set up some of monitoring system so that you know  , because some times in the dev things work okay but  on production  may be doesn't perform as good so having monitoring and updated system  make sure  that your model doesn't do wrong prediction and you are not lossing on your business \n",
    "  > if the model doesn't performing well  you have to get more training data  and repeate the full process  \n",
    "\n",
    "\n",
    "<!--TODO : burada da resim var ekle  -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
